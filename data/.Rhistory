# Kertoimet ovat oikeat
#########################################################################################
#summaryR.lm <- function(model, type=c("hc3", "hc0", "hc1", "hc2", "hc4"), ...){
#
#  if (!require(car)) stop("Required car package is missing.")
#
#  type <- match.arg(type)
#  V <- hccm(model, type=type)
#  sumry <- summary(model)
#  table <- coef(sumry)
#  table[,2] <- sqrt(diag(V))
#  table[,3] <- table[,1]/table[,2]
#  table[,4] <- 2*pt(abs(table[,3]), df.residual(model), lower.tail=FALSE)
#
#  sumry$coefficients <- table
#  p <- nrow(table)
#  hyp <- cbind(0, diag(p - 1))
#  sumry$fstatistic[1] <- linearHypothesis(model, hyp,white.adjust=type)[2,"F"]
#
#  print(sumry)
#  return(sumry)
# cat("Note: Heteroscedasticity-consistent standard errors using adjustment", type, "\n")
#
#}
#################################################################################################
# Lasketaan mallin pitkan- ja lyhyen aikavalin tulojoustot
# Lyhyt
beta_bktTuotot <- 0.025892
kaBkt <- sum(bktPerCapita_t)/length(bktPerCapita_t)
kaTuotot <- sum(kateKotimaa_t)/length(kateKotimaa_t)
tulojoustoSt <- beta_bktTuotot*(kaBkt/kaTuotot)
# Pitka
beta_TuototLagged <- 0.72464
tulojoustoLt <- (beta_bktTuotot/(1-beta_TuototLagged))*(kaBkt/kaTuotottulo)
# 95-porsentin luottamusvali selittavalle muuttujalle
beta <- -2.2902
ser <- 0.60333
luottamusvaliYsiViis <- c(beta - ser*1.96, beta + ser*1.96)
luottamusvaliYsiViis
# Piirretään kuvaaja
plot(vuosi_t ,kateKotimaa_t, ylim = c(0, 2000),type = "o", col = "blue", xlab = "Vuosi", ylab = "Pelituotto = Liikevaihto - Pelaajille maksetut voitot (€)")
lines(vuosi_t, kateUlkomaat_t, type = "o", col  = "red")
plot(vuosi_t ,kateUlkomaat_t, ylim = c(0, 500),type = "o", col = "red", xlab = "Vuosi", ylab = "Pelikate = Liikevaihto - Pelaajille maksetut voitot (€)", main = "Pelikate ulkomaat")
# Piiretään muutoskuvaaja
# Muutokset kotimaan pelikatteille
dKateKotimaa_t <- kateKotimaa_t - kateKotimaa_tMin1
dKateKotimaa_t <- dKateKotimaa_t/kateKotimaa_tMin1
dKateKotimaa_t <- dKateKotimaa_t*100
cbind(dKateKotimaa_t, vuosi_t)
dKateKotimaa2005_2016 <- subset(dKateKotimaa_t, vuosi_t >2004)
mean(dKateKotimaa2005_2016)
# Muutokset ulkomaan pelikatteille
dKateUlkomaat_t <- kateUlkomaat_t - kateUlkomaat_tMin1
dKateUlkomaat_t <- dKateUlkomaat_t/kateUlkomaat_tMin1
dKateUlkomaat_t <- dKateUlkomaat_t*100
dKateUlkomaat_t[dKateUlkomaat_t == 'NaN'] <- 0
dKateUlkomaat_t[dKateUlkomaat_t == 'Inf'] <- 0
cbind(dKateUlkomaat_t, vuosi_t)
dKateUlkomaat2005_2016 <- subset(dKateUlkomaat_t, vuosi_t >2004)
mean(dKateUlkomaat2005_2016)
# Piirettään muutoskuvaaja
plot(vuosi_t ,dKateKotimaa_t, ylim = c(-12, 30), xlim = c(2005,2016), type = "o", col = "blue", xlab = "Vuosi", ylab = "Muutos (%)")
lines(vuosi_t, dKateUlkomaat_t, type = "o", col  = "red")
#########################################################
pelikateKok_t <- kateUlkomaat_t+kateKotimaa_t
pelikateKok_tMin1 <- kateUlkomaat_tMin1+kateKotimaa_tMin1
pelikateMuutos_t <- pelikateKok_t/pelikateKok_tMin1
(pelikateMuutos_t-1)*100
ulkomaidenOsuusTuloista <- kateUlkomaat_t/pelikateKok_t
#########################################################
summary(data_R_kaikki_1990_2016)
250,28*9
250.28*9
3*2200
?head
## In this example, the data is in a matrix called
## data.matrix
## columns are individual samples (i.e. cells)
## rows are measurements taken for all the samples (i.e. genes)
## Just for the sake of the example, here's some made up data...
data.matrix <- matrix(nrow=100, ncol=10)
colnames(data.matrix) <- c(
paste("wt", 1:5, sep=""),
paste("ko", 1:5, sep=""))
rownames(data.matrix) <- paste("gene", 1:100, sep="")
for (i in 1:100) {
wt.values <- rpois(5, lambda=sample(x=10:1000, size=1))
ko.values <- rpois(5, lambda=sample(x=10:1000, size=1))
data.matrix[i,] <- c(wt.values, ko.values)
}
head(data.matrix)
dim(data.matrix)
?prcomp
pca <- prcomp(t(data.matrix), scale=TRUE)
## plot pc1 and pc2
plot(pca$x[,1], pca$x[,2])
## make a scree plot
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
barplot(pca.var.per, main="Scree Plot", xlab="Principal Component", ylab="Percent Variation")
## now make a fancy looking plot that shows the PCs and the variation:
library(ggplot2)
install.packages("ggplot2")
pca.data <- data.frame(Sample=rownames(pca$x),
X=pca$x[,1],
Y=pca$x[,2])
pca.data
ggplot(data=pca.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("My PCA Graph")
library("ggplot2", lib.loc="~/R/win-library/3.4")
ggplot(data=pca.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("My PCA Graph")
library("ggplot2", lib.loc="~/R/win-library/3.4")
install.packages("lazyeval")
install.packages("lazyeval")
library("ggplot2", lib.loc="~/R/win-library/3.4")
## In this example, the data is in a matrix called
## data.matrix
## columns are individual samples (i.e. cells)
## rows are measurements taken for all the samples (i.e. genes)
## Just for the sake of the example, here's some made up data...
data.matrix <- matrix(nrow=100, ncol=10)
colnames(data.matrix) <- c(
paste("wt", 1:5, sep=""),
paste("ko", 1:5, sep=""))
rownames(data.matrix) <- paste("gene", 1:100, sep="")
for (i in 1:100) {
wt.values <- rpois(5, lambda=sample(x=10:1000, size=1))
ko.values <- rpois(5, lambda=sample(x=10:1000, size=1))
data.matrix[i,] <- c(wt.values, ko.values)
}
head(data.matrix)
dim(data.matrix)
pca <- prcomp(t(data.matrix), scale=TRUE)
## plot pc1 and pc2
plot(pca$x[,1], pca$x[,2])
## make a scree plot
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
barplot(pca.var.per, main="Scree Plot", xlab="Principal Component", ylab="Percent Variation")
## now make a fancy looking plot that shows the PCs and the variation:
library(ggplot2)
install.packages("rlang")
install.packages("rlang")
install.packages("tidyverse", dependencies = TRUE)
## now make a fancy looking plot that shows the PCs and the variation:
library(ggplot2)
pca.data <- data.frame(Sample=rownames(pca$x),
X=pca$x[,1],
Y=pca$x[,2])
pca.data
ggplot(data=pca.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("My PCA Graph")
## get the name of the top 10 measurements (genes) that contribute
## most to pc1.
loading_scores <- pca$rotation[,1]
gene_scores <- abs(loading_scores) ## get the magnitudes
gene_score_ranked <- sort(gene_scores, decreasing=TRUE)
top_10_genes <- names(gene_score_ranked[1:10])
top_10_genes ## show the names of the top 10 genes
pca$rotation[top_10_genes,1] ## show the scores (and +/- sign)
svd.stuff <- svd(scale(t(data.matrix), center=TRUE))
## calculate the PCs
svd.data <- data.frame(Sample=colnames(data.matrix),
X=(svd.stuff$u[,1] * svd.stuff$d[1]),
Y=(svd.stuff$u[,2] * svd.stuff$d[2]))
svd.data
## alternatively, we could compute the PCs with the eigen vectors and the
## original data
svd.pcs <- t(t(svd.stuff$v) %*% t(scale(t(data.matrix), center=TRUE)))
svd.pcs[,1:2] ## the first to principal components
svd.df <- ncol(data.matrix) - 1
svd.var <- svd.stuff$d^2 / svd.df
svd.var.per <- round(svd.var/sum(svd.var)*100, 1)
ggplot(data=svd.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", svd.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", svd.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("svd(scale(t(data.matrix), center=TRUE)")
############################################
##
## Now let's do the same thing with eigen()
##
## eigen() returns two things...
## vectors = eigen vectors (vectors of loading scores)
##           NOTE: pcs = sum(loading scores * values for sample)
## values = eigen values
############################################
cov.mat <- cov(scale(t(data.matrix), center=TRUE))
dim(cov.mat)
## since the covariance matrix is symmetric, we can tell eigen() to just
## work on the lower triangle with "symmetric=TRUE"
eigen.stuff <- eigen(cov.mat, symmetric=TRUE)
dim(eigen.stuff$vectors)
head(eigen.stuff$vectors[,1:2])
eigen.pcs <- t(t(eigen.stuff$vectors) %*% t(scale(t(data.matrix), center=TRUE)))
eigen.pcs[,1:2]
eigen.data <- data.frame(Sample=rownames(eigen.pcs),
X=(-1 * eigen.pcs[,1]), ## eigen() flips the X-axis in this case, so we flip it back
Y=eigen.pcs[,2]) ## X axis will be PC1, Y axis will be PC2
eigen.data
eigen.var.per <- round(eigen.stuff$values/sum(eigen.stuff$values)*100, 1)
ggplot(data=eigen.data, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC1 - ", eigen.var.per[1], "%", sep="")) +
ylab(paste("PC2 - ", eigen.var.per[2], "%", sep="")) +
theme_bw() +
ggtitle("eigen on cov(t(data.matrix))")
?martix
?matrix()
X <- matrix(c(1,3,1,2,1,0), nrow = 3)
X
X <- matrix(c(1,1,1,3,2,0), nrow = 3)
X
beta_real <- matrix(c(-1,2), nrow = 2)
beta_real
epsilon <- (c(-0.1, 0.4, -0.3), nrow = 3)
epsilon <- matrix(c(-0.1, 0.4, -0.3), nrow = 3)
epsi
epsilon
epsilon_real <- matrix(c(-0.1, 0.4, -0.3), nrow = 3)
epsilon_real
X <- matrix(c(1,1,1,3,2,0), nrow = 3)
X
beta_real <- matrix(c(-1,2), nrow = 2)
beta_real
epsilon_real <- matrix(c(-0.1, 0.4, -0.3), nrow = 3)
epsilon_real
epsilon_act <- matrix(c(-0.1, 0.4, -0.3), nrow = 3)
epsilon_act   #Simulated from normal disripution, mean = 0 and standard deviation = 0.1
y_act <- X*beta_real + epsilon_act
y_act <- X*beta_real
X
beta_real
y_act <- X%*%beta_real + epsilon_act
y_act
lm(y_act~X)
projection_x <- X
count_prjojection(X, projection_x)
count_prjojection <-  function(X, projection_x) {
projection_x<-t(X)%*%X
projection_x<-solve(projection_x)
projection_x<-X%*%projection_x
projection_x<-projection_x%*%t(X)
}
projection_x <- X
count_prjojection(X, projection_x)
projection_x
projection_x <- X
projection_x
count_prjojection(X, projection_x)
projection_x
count_prjojection <-  function(X) {
projection_x<-t(X)%*%X
projection_x<-solve(projection_x)
projection_x<-X%*%projection_x
projection_x<-projection_x%*%t(X)
return(projection_x)
}
count_prjojection(X)
projection_x<-count_prjojection(X)
projection_x
y_hat <- projection_x%*%y_act
y_hat
I <- matrix(c(1,0,0,0,1,0,0,0,1), nrow = 3)
I
residual <-(I-projection_x)%*%y_act
residual
X
X1 <- matrix(c(1,1,1), nrow = 3)
X1
X2<- matrix(c(3,2,0), nrow = 3)
X2
projection_x1 <- count_prjojection(X1)
I
Mx1 <- I - projection_x1
Mx1%*%X2
Mx1%*%X1
projection_x
eigen_projection_x <- eigen(projection_x)
eigen_projection_x$values
eigen_projection_x1 <- eigen(projection_x1)
eigen_projection_x1$values
library(readr)
talon_kulmat <- read_csv("Random kansio/talon_kulmat.txt")
View(talon_kulmat)
coordinates_matrix <- talon_kulmat
schoelace_fun <- function(coordinates) {
areas <- rep.int(0, nrow(coordinates))
for(i in 1:c(nrow(coordinates)-1)) {
det <- coordinates[i,1]*coordinates[i+1,2]-coordinates[i+1,1]*coordinates[i,2]
area <- 0.5*det
areas[i] <- area
}
print(sum(areas))
}
area_house_px <- schoelace_fun(coordinates_matrix)
coordinates_matrix <- as.matrx(talon_kulmat)
coordinates_matrix <- matrix(talon_kulmat)
coordinates_matrix
coordinates_matrix <- as.matrix(talon_kulmat)
coordinates_matrix
schoelace_fun <- function(coordinates) {
areas <- rep.int(0, nrow(coordinates))
for(i in 1:c(nrow(coordinates)-1)) {
det <- coordinates[i,1]*coordinates[i+1,2]-coordinates[i+1,1]*coordinates[i,2]
area <- 0.5*det
areas[i] <- area
}
print(sum(areas))
}
area_house_px <- schoelace_fun(coordinates_matrix)
area_house_real <- 78
scaler <- sqrt(area_house_real/-area_house_px)
lengths_fun <- function(coordinates){
lengths <- rep.int(0,nrow(coordinates)-1)
for(j in 1:c(nrow(coordinates)-1)) {
dif_y <- coordinates[j,2] - coordinates[j+1,2]
dif_x <- coordinates[j,1] - coordinates[j+1,1]
length <- sqrt((dif_y^2)+(dif_x^2))
lengths[j] <- length
}
print(scaler*lengths)
}
lengths_fun(coordinates_matrix)
View(coordinates_matrix, "Seinien pituudet")
length_walls <- lengths_fun(coordinates_matrix)
View(length_walls, "Seinien pituudet")
?sink()
length_walls <- capture.output(lengths_fun(coordinates_matrix))
cat("Seinien pituudet", length_walls, file = "C:/Users/juhol/OneDrive/Documents/seinien_pituudet.csv", sep = "n")
getwd()
setwd("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project")
getwd()
data_student_mat <- read.csv("/c/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data/student/student-mat.csv", header = T, sep = ";")
data_student_mat <- read.csv("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data/student/student-mat.csv", header = T, sep = ";")
View(data_student_mat)
data_student-por <- read.csv("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data/student/student-por.csv", header = T, sep = ";")
data_student_por <- read.csv("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data/student/student-por.csv", header = T, sep = ";")
View(data_student_por)
####################################################################
# Packages
library(dplyr)
# common columns to use as identifiers
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
colnames(data_student_mat)
str(data_student_mat)
summary(data_student_mat)
dim(data_student_mat)
colnames(data_student_por)
str(data_student_por)
dim(data_student_por)
summary(data_student_por)
# Juho Lahteenmaa
# 13/11/2018
# Data wrangling, week 3, data "Student Performance Data Set"
# https://archive.ics.uci.edu/ml/datasets/Student+Performance
####################################################################
# Packages
library(dplyr)
####################################################################
# Lets read both student-mat.csv and student-por.csv from data/student/ directory
data_student_mat <- read.csv("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data/student/student-mat.csv", header = T, sep = ";")
colnames(data_student_mat)
str(data_student_mat)
dim(data_student_mat)
summary(data_student_mat)
#View(data_student_mat)
data_student_por <- read.csv("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data/student/student-por.csv", header = T, sep = ";")
colnames(data_student_por)
str(data_student_por)
dim(data_student_por)
summary(data_student_por)
#View(data_student_por)
# Lets combine datasets
# common columns to use as identifiers
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
# join the two datasets by the selected identifiers
math_por <- inner_join(data_student_mat, data_student_por, by = join_by, suffix = c(".math", ".por"))
colnames(math_por)
str(math_por)
str(math_por)
str(math_por)
dim(math_por)
summary(math_por)
View(math_por)
# create a new data frame with only the joined columns
alc <- select(math_por, one_of(join_by))
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]
# print out the columns not used for joining
notjoined_columns
# for every column name not used for joining...
for(column_name in notjoined_columns) {
# select two columns from 'math_por' with the same original name
two_columns <- select(math_por, starts_with(column_name))
# select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
# if that first column vector is numeric...
if(is.numeric(first_column)) {
# take a rounded average of each row of the two columns and
# add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
# add the first column vector to the alc data frame
alc[column_name] <- first_column
}
}
# glimpse at the new combined data
glimpse(alc)
# define a new column alc_use by combining weekday and weekend alcohol use
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
glimpse(alc)
notjoined_columns
# create a new data frame with only the joined columns
alc <- select(math_por, one_of(join_by))
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]
# print out the columns not used for joining
notjoined_columns
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]
# create a new data frame with only the joined columns
alc <- select(math_por, one_of(join_by))
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(data_student_mat)[!colnames(data_student_mat) %in% join_by]
# print out the columns not used for joining
notjoined_columns
for(column_name in notjoined_columns) {
# select two columns from 'math_por' with the same original name
two_columns <- select(math_por, starts_with(column_name))
# select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
# if that first column vector is numeric...
if(is.numeric(first_column)) {
# take a rounded average of each row of the two columns and
# add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
# add the first column vector to the alc data frame
alc[column_name] <- first_column
}
}
# glimpse at the new combined data
glimpse(alc)
# define a new column alc_use by combining weekday and weekend alcohol use
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
# define a new logical column 'high_use'
alc <- mutate(alc, high_use = alc_use > 2)
glimpse(alc)
getwd()
setwd("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data")
getwd()
write.csv(alc, file = "alc.csv")
alc <- read.csv("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data/alc.csv", header = T, sep = ",")
alc <- read.csv("C:/Users/juhol/OneDrive/Documents/GitHub/IODS-project/data/alc.csv", header = T, sep = ",")
dim(alc)
str(alc)
View(alc)
?read.csv
alc <- alc[,-1]
dim(alc)
str(alc)
View(alc)
summary(alc)
colnames(alc)
variables_sub <- c("sex", "age", "activities", "romantic", "famrel", "goout", "high_use")
alc_sub <- select(alc, one_of(variables_sub))
str(alc_sub)
ggpairs(alc_sub, lower = list(combo = wrap("facethist", bins = 20)))
library(dplyr)
library(tidyverse)
library(ggplot2)
library(car)
library(sandwich)
library(lmtest)
ggpairs(alc_sub, lower = list(combo = wrap("facethist", bins = 20)))
library(ggplot2)
ggpairs(alc_sub, lower = list(combo = wrap("facethist", bins = 20)))
library(GGally)
ggpairs(alc_sub, lower = list(combo = wrap("facethist", bins = 20)))
ggpairs(alc_sub, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
ggpairs(alc_sub, mapping = aes(col = sex, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
?ggpairs
str(alc_sub)
alc_sex <- ggplot(data = alc_sub, aes(x = high_use, fill = sex)) + geom_bar() + ggtitle("Student consumption of alcohol and sex")
alc_sex
alc_age <- ggplot(data = alc_sub, aes(x = sex, fill = high_use)) + geom_bar() + ggtitle("Student consumption of alcohol and sex")
alc_sex <- ggplot(data = alc_sub, aes(x = high_use, fill = sex)) + geom_bar() + ggtitle("Student consumption of alcohol and sex")
alc_sex
alc_sex <- ggplot(data = alc_sub, aes(x = sex, fill = high_use)) + geom_bar() + ggtitle("Student consumption of alcohol and sex")
alc_sex
alc_age <- ggplot(data = alc_sub, aes(x = age, fill = high_use)) + geom_bar() + ggtitle("Student consumption of alcohol and age")
alc_age
alc_act <- ggplot(data = alc_sub, aes(x = activities, fill = high_use)) + geom_bar() + ggtitle("Student consumption of alcohol and activities")
alc_act
alc_rom <- ggplot(data = alc_sub, aes(x = romantic, fill = high_use)) + geom_bar() + ggtitle("Student consumption of alcohol and romantic relationship")
alc_rom
alc_rom
